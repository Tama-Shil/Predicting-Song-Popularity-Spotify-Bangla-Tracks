# -*- coding: utf-8 -*-
"""NormalizationOfDataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y2vELBC2rGpDalwp733Pir9HjQo9Ou0x

**importing necessary libraries**
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

"""**dividing dataset into features and target class**"""

file_path = '/content/data(raw audio features).csv'
SBT = pd.read_csv(file_path)
SBT_normalized = SBT
features = ['danceability', 'energy','key', 'loudness', 'speechiness', 'acousticness',
            'instrumentalness', 'liveness', 'valence', 'tempo', 'duration', 'time_signature']

X = SBT[features]
Y = SBT.popularity
X.head()

"""**normalizing the whole dataset**"""

features = ['danceability', 'energy','key', 'loudness', 'speechiness', 'acousticness','instrumentalness',
            'liveness', 'valence', 'tempo', 'duration', 'time_signature', 'popularity']
norm = MinMaxScaler().fit(SBT[features])
SBT_normalized = norm.transform(SBT[features])
SBT_normalized_df = pd.DataFrame(SBT_normalized, columns= SBT[features].columns)
SBT_normalized_df.to_csv('SBT_normalized_dataset.csv', index=False)

def normalize_popularity(pop):
    return (pop - Y.min()) / (Y.max() - Y.min())

dataset_df = pd.read_csv('/content/data(raw audio features).csv')
normalized_df = pd.read_csv('SBT_normalized_dataset.csv')
first_five_columns = dataset_df.iloc[:, :5]
merged_df = pd.concat([first_five_columns, normalized_df], axis=1)
merged_df['popularity'] = merged_df['popularity'].apply(normalize_popularity)
merged_df.to_csv('SBT_normalized_dataset.csv', index=False)

"""## **Splitting training and test dataset** (thik korte hobe pore)"""

# To divide the dataset into training and test sets

X_train, X_test, y_train, y_test = train_test_split(X, Y ,test_size=0.2)
X_train.head()

"""## **Min-Max normalization**"""

# Good practice to keep original dataframes untouched for reusability
X_train_n = X_train.copy()
X_test_n = X_test.copy()

# Fit min-max scaler on training data
norm = MinMaxScaler().fit(X_train_n)

# Transform the training data
X_train_norm = norm.transform(X_train_n)

# Use the same scaler to transform the testing set
X_test_norm = norm.transform(X_test_n)

X_train_norm_df = pd.DataFrame(X_train_norm, columns=X.columns)


X_train_norm_df.head()


min_y_train = y_train.min()
max_y_train = y_train.max()

y_train_norm = (y_train - min_y_train) / (max_y_train - min_y_train)
y_train_norm = (y_train - min_y_train) / (max_y_train - min_y_train)


min_y_test = y_test.min()
max_y_test = y_test.max()

y_test_norm = (y_test - min_y_test) / (max_y_test - min_y_test)
y_test_norm = (y_test - min_y_test) / (max_y_test - min_y_test)

# Print the DataFrame with the normalized column
print(y_train_norm)
print(y_test_norm)

print(X_train_norm_df.dtypes)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
# Create a Linear Regression model
linear_reg_model_encoded = LinearRegression()

# Train the Linear Regression model on the training set
linear_reg_model_encoded.fit(X_train_norm, y_train_norm)

# Make predictions using the Linear Regression model
y_pred_lr_encoded = linear_reg_model_encoded.predict(X_test_norm)

# Evaluate the Linear Regression model
mse_lr_encoded = mean_squared_error(y_test_norm, y_pred_lr_encoded)
r2_lr_encoded = r2_score(y_test_norm, y_pred_lr_encoded)

print(f'Linear Regression Mean Squared Error: {mse_lr_encoded}')
print(f'Linear Regression R-squared: {r2_lr_encoded}')

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
# Create a Random Forest Regressor model
rf_model_encoded = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the Random Forest model on the training set
rf_model_encoded.fit(X_train_norm, y_train_norm)

# Make predictions using the Random Forest model
y_pred_rf_norm = rf_model_encoded.predict(X_test_norm)

# Evaluate the Random Forest model
mse_rf_encoded = mean_squared_error(y_test_norm, y_pred_rf_norm)
r2_rf_encoded = r2_score(y_test_norm, y_pred_rf_norm)

print(f'Random Forest Mean Squared Error: {mse_rf_encoded}')
print(f'Random Forest R-squared: {r2_rf_encoded}')

from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
# Create an SVR model
svr_model_encoded = SVR(kernel='linear', C=1.0)  # You can adjust the kernel and C parameter as needed

# Train the model on the training set
svr_model_encoded.fit(X_train_norm, y_train_norm)

# Make predictions using the SVR model
y_pred_svr_encoded = svr_model_encoded.predict(X_test_norm)

# Evaluate the SVR model
mse_svr_encoded = mean_squared_error(y_test_norm, y_pred_svr_encoded)
r2_svr_encoded = r2_score(y_test_norm, y_pred_svr_encoded)

print(f'SVR Mean Squared Error: {mse_svr_encoded}')
print(f'SVR R-squared: {r2_svr_encoded}')